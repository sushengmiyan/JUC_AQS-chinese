# **java.util.concurrent同步框架**

Doug Lea

SUNY Oswego

Oswego NY 13126

dl@cs.oswego.edu

## **摘要**

在J2SE 1.5的java.util.concurrent包中，大部分的同步器（例如锁，屏障等）都是基于AbstractQueuedSynchronizer这个类的简单框架而构建的。这个框架为同步状态的原子性管理、线程的阻塞和解除阻塞以及队列提供了一种通用的机制。本文介绍了这个框架的原理、设计、实现、用法和性能。

## **目录和主题描述**

D.1.3[编程技术]:并发编程-并行编程

**一般条款**

算法，测量，性能，设计。

**关键字**

Synchronization, Java

## 1.****介绍****

Java发行版本 J2SE-1.5通过 Java Community Process(JCP)的Java Specification Request(JSR)166引入了包java.util.concurrent。

这个包提供了一系列创建中级并发支持类的集合。在这些组件中有一组同步器——抽象数据类型(ADT)类，它们维护内部同步状态(例如，表示锁是锁定的还是未锁定的)，更新和检查状态的操作，如果状态需要，至少有一个方法会导致调用线程阻塞，当其他线程更改同步状态时允许它恢复。示例包括各种形式的互斥锁、读写锁、信号量、屏障、预期futures、事件指示器和切换队列。

众所周知(如[2])，几乎任何同步器都可以用来实现几乎任何其他同步器。例如，可以从可重入锁构建信号量，反之亦然。然而，这样做通常需要足够的复杂性、开销和灵活性，充其量只能成为二流的项目选择。此外，它在概念上没有吸引力。如果这些构造在本质上没有一个比其他构造更简介，那么开发人员不应该被迫任意选择其中一个来作为构建其他构造的基础。相反，JSR166建立了一个以AbstractQueuedSynchronizer类为中心的小框架，它提供了大多数同步器以及用户可能自己定义的其他类所使用的公共机制。本文的其余部分将讨论此框架的需求、其设计和实现背后的主要思想、示例用法以及显示其性能特征的一些度量。

## 2.****需求****


### 2.1 **功能需求**

同步器一般包含两种方法[7]，一种是acquire，另一种是release。acquire操作阻塞调用的线程，直到或除非同步状态允许其继续执行。而release操作则是通过某种方式改变同步状态，使得一个或多个被acquire阻塞的线程继续执行。

java.util.concurrent包并没有给同步器的API做一个统一的定义。有些是通过公共接口(例如锁)定义的，但是其他的只包含特定的版本。因此在不同的类中，acquire和release操作的名字和形式会各有不同。例如：Lock.lock，Semaphore.acquire，CountDownLatch.await和FutureTask.get，在这个框架里，这些方法都是acquire操作。但是，为支持一系列通用的使用选项，在类间都有个一致约定。当有意义时，每个同步器都支持：

非阻塞同步尝试(例如，tryLock)以及阻塞同步尝试。

可选的超时设置，因此应用程序可以选择放弃等待。

通过中断的可取消性，通常分为一个可取消的获取版本和一个不可取消的获取版本。

同步器可能会根据它们是否只管理独占状态(即一次只有一个线程在可能的阻塞点之后继续运行)和共享状态(至少有多个线程可以同时继续运行)而有所不同。常规锁类当然只维护独占状态，但是计数信号量可以由计数允许的尽可能多的线程获得。要广泛使用，框架必须支持这两种操作模式。

ava.util.concurrent包也定义了Condition接口，支持监视器风格的等待/信号操作，这些操作可能与独占锁类Lock相关联，并且其实现本质上与其关联的锁类Lock交织在一起。

### 2.2 **性能目标**

Java内置锁(使用synchronized的方法或代码块是一直以来都在被人们关注的性能问题，并且已经有一系列的文章描述其构造（例如引文[1],[3]）。然而，这类工作的主要焦点是最小化空间开销(因为任何Java对象都可以用作锁)，以及在单处理器上的单线程上下文中最小化时间开销。这些都不是某个特别重要的问题:程序员只在需要的时候才会构建同步器,因此不需要压缩空间,并且同步器几乎是专门用在多线程设计中(越来越频繁地在多处理器),这种情况下，偶尔争用是在预料之中的。因此，常规的JVM优化锁策略主要针对零争用情况，而将其他情况留给不那么可预测的“慢路径”[12]，对于严重依赖java.util.concurrent的典型多线程服务器应用程序来说，常规的策略并不适用。

相反，这里的主要性能目标是可伸缩性:即使在争用同步器时，也可预测地保持效率，尤其是在争用同步器时。理想情况下，无论有多少线程尝试通过同步点，通过同步点所需的开销都应该是常量。在某一线程被允许通过同步点但还没有通过的情况下，使其耗费的总时间最少，这是主要目标之一。但是，这必须与资源考虑因素相平衡，包括总CPU时间需求、内存流量和线程调度开销。例如，自旋锁通常比阻塞锁提供更短的获取时间，但通常会浪费周期并产生内存争用，因此通常不常用。

这些目标包含两种一般的使用风格。大多数应用程序应该最大限度地提高总吞吐量，最多也只能容忍对减少饥饿的概率保证。然而，在资源控制等应用程序中，维护线程间访问的公平性要重要得多，这可以容忍较差的聚合吞吐量。没有一个框架能够代表用户在这些冲突的目标之间做出决定;相反，必须适应不同的公平政策。

不管同步器的内部设计有多好，它们都是同步器，将在某些应用程序中产生性能瓶颈。因此，框架必须能够监视和检查基本操作，以允许用户发现和缓解瓶颈。这至少(也是最有用的)需要提供一种方法来确定有多少线程被阻塞。

 

 

 
