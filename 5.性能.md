5.性能
====

虽然同步器框架除了互斥锁之外还支持许多其他类型的同步，但是锁的性能是最容易测量和比较的。<br>
即便如此，还是有许多不同的测量方法。这里的实验旨在揭示开销和吞吐量。<br>
在每个测试中，每个线程都重复地更新使用函数计算的伪随机数：<br>
```
nextRandom(int seed):
int t = (seed % 127773) * 16807 –
(seed / 127773) * 2836;
return (t > 0)? t : t + 0x7fffffff;
```
在每个迭代中，一个线程以概率S更新互斥锁下的共享生成器，否则它将在没有锁的情况下更新自己的本地生成器。<br>
这将导致短时间的锁定区域，当线程在持有锁时被抢占时，会将无关的影响降到最低。<br>
函数的随机性有两个目的:它用于决定是否锁定(对于当前的目的，它是一个足够好的生成器)，还使得循环内的代码不可能被简单地优化掉。<br>
比较了四种锁:内置锁、同步锁;互斥量，使用一个简单的互斥量类，如第4节所示;可重入,使用ReentrantLock;并且公平，使用在其“公平”模式中设置的ReentrantLock。<br>
所有测试都使用Sun J2SE1.5 JDK在“server"模式下的build 46(与beta2大致相同)。测试程序在收集测量值之前执行20次非竞争运行，以消除热身效果。<br>
每个线程运行1000万个迭代的测试，除了公平模式测试只运行100万个迭代。
在4台基于x86的机器和4台基于UltraSparc的机器上进行了测试。所有x86机器都使用基于RedHat nptl的2.4内核和库运行Linux。<br>
所有超parc机器都在运行Solaris-9。在测试时，所有系统的负载都很轻。测试的性质并不要求它们完全空闲。<br>
“4P”名称反映了一个事实，即双超线程(HT) Xeon的行为更像一个4路而不是2路机器。这里没有试图使分歧正常化。<br>
如下所示，同步的相对成本与处理器的数量、类型或速度没有简单的关系。<br>

![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/003.jpg)

5.1开销
--

无争用开销是通过只运行一个线程来度量的，用S=1的运行减去版本设置为S=0(访问共享随机的概率为0)时每次迭代所花费的时间。<br>
表2显示了同步代码对非同步代码的每次锁开销的估计，单位为纳秒。互斥类最接近于测试框架的基本成本。<br>
重入锁的额外开销指示记录当前所有者线程和错误检查的成本，而对于公平锁，则指示首先检查队列是否为空的额外成本。<br>

表2还显示了tryacquisition的成本与内置锁的“快速路径”的比较。这里的差异主要反映了跨锁和机器使用不同原子指令和内存屏障的成本。<br>
在多处理器上，这些指令往往完全压倒其他所有指令。<br>
内建类和同步器类之间的主要区别显然是由于热点锁使用compareAndSet进行锁定和解锁，而这些同步器使用compareAndSet进行获取和volatile写(即，在多处理器上设置内存屏障，并在所有处理器上重新排序约束)。每种机器的绝对成本和相对成本各不相同。<br>

在另一个极端，表3显示了每个锁的开销，S=1，运行256个并发线程，导致大量锁争用。<br>
在完全饱和的情况下，bar- fifo锁的开销比内置锁低一个数量级(相当于更高的吞吐量)，通常比公平锁低两个数量级。<br>
这证明了bar- fifo策略在极端争用情况下保持线程进程的有效性。<br>

![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/004.jpg)
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/005.jpg)

表3还说明，即使内部开销很低，上下文切换时间也完全决定了公平锁的性能。列出的时间大致与在各种平台上阻塞和解除阻塞线程的时间成正比。<br>
此外，后续的实验(仅使用machine 4P)表明，对于这里使用的非常短暂的持有锁，公平性设置对总体方差的影响很小。<br>
线程终止时间的差异被记录为粗粒度的可变性度量。在机器4P上运行的时间的标准差为平均值的0.7%，而在可重入性上为6.0%。<br>
相反，为了模拟长时间持有的锁，运行了一个版本的测试，其中每个线程在持有每个锁的同时计算16K个随机数。<br>
在这里，总运行时间几乎相同(Fair为9.79秒，Reentrant为9.72秒)。均匀模式变异性仍然很小，标准差为均值的0.1%，而可重入性上升到均值的29.5%。<br>

5.2吞吐量
--

大多数同步器的使用将介于无争用和饱和的极端之间。通过改变一组固定线程的争用概率和/或向一组具有固定争用概率的线程添加更多的线程，可以从两个维度对其进行实验检验。为了说明这些效果，我们使用不同的争用概率和线程数运行测试，所有这些测试都使用可重入锁。相关数据使用了一个放缓指标：<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/006.jpg)<br>
这里，t为观察到的总执行时间，b为一个没有争用或同步的线程的基线时间，n为线程数，p为处理器数，S为共享访问的比例。<br>
这个值是观察到的时间与(通常无法达到的)理想执行时间的比值，使用Amdahl定律计算了顺序和并行任务的混合。<br>
理想时间为执行建模，在没有任何同步开销的情况下，不会因为与其他线程发生冲突而导致线程阻塞。<br>
即便如此，在非常低的争用情况下，一些测试结果显示的速度与理想情况相比非常小，这可能是由于基线与测试运行之间的优化、管道等方面的细微差异造成的。<br>
这些数字使用以2为底的对数刻度。例如，值1.0表示测量时间是理想情况下时间的两倍，值4.0表示慢16倍。<br>
logsameliorates的使用依赖于任意的基本时间(这里是计算随机数的时间)，因此不同基础计算的结果应该显示类似的趋势。<br>
测试使用的争用概率从1/128(标记为“0.008”)到1，步进2的幂次，线程数从1到1024，步进2的半幂次。<br>
在单处理器上(1P和1U)，性能随着争用的增加而下降，但通常不会随着线程数量的增加而下降。多处理器在争用下通常会遇到更糟糕的慢速。<br>
多处理器的图表显示了一个早期的峰值，在这个峰值中，只涉及几个线程的争用通常会产生最差的相对性能。<br>
这反映了性能的一个过渡区域，在这个过渡区域中，barging和发出信号的线程获得锁的可能性大致相同，因此常常相互阻塞。<br>
在大多数情况下，这之后是一个更平滑的区域，因为锁几乎永远不可用，导致访问类似于单处理器的近顺序模式;在拥有更多处理器的机器上更快地实现这一点。<br>
例如，请注意，在处理器较少的机器上，全争用的值(标记为“1.000”)表现出相对较差的慢速。<br>

![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/007.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/008.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/009.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/010.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/011.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/012.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/013.jpg)<br>
![image](https://github.com/sushengmiyan/JUC_start/blob/master/images/014.jpg)<br>
根据这些结果，进一步调优阻塞(park/unpark)支持，以减少上下文切换和相关开销，似乎可以在这个框架中提供小而明显的改进。<br>
此外，同步器类为多处理器上的briefly持有的高度争用锁采用某种形式的自适应旋转，以避免这里看到的一些抖动，这可能会带来好处。<br>
虽然自适应自旋很难在不同的上下文中很好地工作，但是可以使用这个框架构建自定义形式的锁，针对遇到这种使用概要的特定应用程序。<br>





